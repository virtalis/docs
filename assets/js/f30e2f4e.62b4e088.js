"use strict";(self.webpackChunkvirtalis_docs=self.webpackChunkvirtalis_docs||[]).push([[8138],{42157:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>s,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"glossary","title":"Glossary","description":"This page lists terminology that we use in our software and documentation. It includes both standard industry terms and terms specific to our products.","source":"@site/docs/glossary.mdx","sourceDirName":".","slug":"/glossary","permalink":"/glossary","draft":false,"unlisted":false,"editUrl":"https://github.com/virtalis/docs/tree/master/docs/glossary.mdx","tags":[],"version":"current","lastUpdatedAt":1743659126000,"frontMatter":{}}');var a=t(74848),r=t(28453);const s={},o="Glossary",l={},d=[{value:"Ambient",id:"ambient",level:3},{value:"Ancestor",id:"ancestor",level:3},{value:"Animation",id:"animation",level:3},{value:"Animation Sequencer",id:"animation-sequencer",level:3},{value:"Annotate",id:"annotate",level:3},{value:"Annotations",id:"annotations",level:3},{value:"Apps",id:"apps",level:3},{value:"Artifact",id:"artifact",level:3},{value:"Aspect Ratio",id:"aspect-ratio",level:3},{value:"Assembly",id:"assembly",level:3},{value:"Assets",id:"assets",level:3},{value:"Augmented Reality",id:"augmented-reality",level:3},{value:"Avatar",id:"avatar",level:3},{value:"Bandwidth",id:"bandwidth",level:3},{value:"Cave Automatic Virtual Environment (CAVE)",id:"cave-automatic-virtual-environment-cave",level:3},{value:"Character Controller",id:"character-controller",level:3},{value:"Chroma Keying",id:"chroma-keying",level:3},{value:"Collision Detection",id:"collision-detection",level:3},{value:"Comments",id:"comments",level:3},{value:"Computer-Aided Design (CAD)",id:"computer-aided-design-cad",level:3},{value:"Data Source",id:"data-source",level:3},{value:"Data Source Adapter",id:"data-source-adapter",level:3},{value:"Degrees of Freedom (3DOF, 6DOF)",id:"degrees-of-freedom-3dof-6dof",level:3},{value:"Diagnostics",id:"diagnostics",level:3},{value:"Dimension",id:"dimension",level:3},{value:"Dual GPU Parallel",id:"dual-gpu-parallel",level:3},{value:"Emissive",id:"emissive",level:3},{value:"Entity Filters",id:"entity-filters",level:3},{value:"External Data",id:"external-data",level:3},{value:"Eye Tracking",id:"eye-tracking",level:3},{value:"Factory Reset",id:"factory-reset",level:3},{value:"Fast Approximate Anti-aliasing (FXAA)",id:"fast-approximate-anti-aliasing-fxaa",level:3},{value:"Field of View (FOV)",id:"field-of-view-fov",level:3},{value:"Frames per Second (FPS)",id:"frames-per-second-fps",level:3},{value:"Frame Rate (30fps and 60fps)",id:"frame-rate-30fps-and-60fps",level:3},{value:"Gallery",id:"gallery",level:3},{value:"Geometric Shapes",id:"geometric-shapes",level:3},{value:"Graphical User Interface (GUI)",id:"graphical-user-interface-gui",level:3},{value:"Haptics",id:"haptics",level:3},{value:"Head Mounted Display (HMD)",id:"head-mounted-display-hmd",level:3},{value:"Head Tracking",id:"head-tracking",level:3},{value:"Head-Up Display (HUD)",id:"head-up-display-hud",level:3},{value:"Headlight",id:"headlight",level:3},{value:"Heatmap",id:"heatmap",level:3},{value:"Helpers",id:"helpers",level:3},{value:"High-Definition Rendering (HDR)",id:"high-definition-rendering-hdr",level:3},{value:"Immersion",id:"immersion",level:3},{value:"Import",id:"import",level:3},{value:"Interpupillary Distance (IPD)",id:"interpupillary-distance-ipd",level:3},{value:"Input",id:"input",level:3},{value:"Interpolation",id:"interpolation",level:3},{value:"Isolate",id:"isolate",level:3},{value:"Judder",id:"judder",level:3},{value:"Labels",id:"labels",level:3},{value:"Last World Click",id:"last-world-click",level:3},{value:"Latency",id:"latency",level:3},{value:"Level of Detail (LOD)",id:"level-of-detail-lod",level:3},{value:"Locomotion",id:"locomotion",level:3},{value:"Lua",id:"lua",level:3},{value:"Map Matrix",id:"map-matrix",level:3},{value:"Material",id:"material",level:3},{value:"Merge",id:"merge",level:3},{value:"Metadata",id:"metadata",level:3},{value:"Mixed Reality",id:"mixed-reality",level:3},{value:"Networking",id:"networking",level:3},{value:"Node",id:"node",level:3},{value:"Occlusion",id:"occlusion",level:3},{value:"Opacity",id:"opacity",level:3},{value:"Pitch",id:"pitch",level:3},{value:"Pivot",id:"pivot",level:3},{value:"Plugin",id:"plugin",level:3},{value:"Point of View (POV)",id:"point-of-view-pov",level:3},{value:"Position Tracking",id:"position-tracking",level:3},{value:"Positional Audio",id:"positional-audio",level:3},{value:"Precision",id:"precision",level:3},{value:"Product Lifecycle Management (PLM) Database",id:"product-lifecycle-management-plm-database",level:3},{value:"Project",id:"project",level:3},{value:"Properties",id:"properties",level:3},{value:"Property Tracks",id:"property-tracks",level:3},{value:"PRS Manipulator",id:"prs-manipulator",level:3},{value:"Quad Buffered",id:"quad-buffered",level:3},{value:"Reflectivity",id:"reflectivity",level:3},{value:"Resolution (1080p - 16K)",id:"resolution-1080p---16k",level:3},{value:"Review",id:"review",level:3},{value:"Rule",id:"rule",level:3},{value:"Saturation",id:"saturation",level:3},{value:"Sequencer",id:"sequencer",level:3},{value:"Sequences",id:"sequences",level:3},{value:"Side-by-Side: Anamorphic",id:"side-by-side-anamorphic",level:3},{value:"Side-by-Side: Square",id:"side-by-side-square",level:3},{value:"Signposts",id:"signposts",level:3},{value:"Single GPU Parallel",id:"single-gpu-parallel",level:3},{value:"Smoothness",id:"smoothness",level:3},{value:"Snap",id:"snap",level:3},{value:"Snapshot",id:"snapshot",level:3},{value:"Software Development Kit (SDK)",id:"software-development-kit-sdk",level:3},{value:"Start Room",id:"start-room",level:3},{value:"Stereo 3D",id:"stereo-3d",level:3},{value:"Stereo Cursor",id:"stereo-cursor",level:3},{value:"Stereoscopic",id:"stereoscopic",level:3},{value:"Teleportation",id:"teleportation",level:3},{value:"Template",id:"template",level:3},{value:"Tethered Headset / Mobile Headset",id:"tethered-headset--mobile-headset",level:3},{value:"Texture",id:"texture",level:3},{value:"Timeline",id:"timeline",level:3},{value:"Timings",id:"timings",level:3},{value:"Toolbar",id:"toolbar",level:3},{value:"Tracking",id:"tracking",level:3},{value:"Transformation",id:"transformation",level:3},{value:"Translation",id:"translation",level:3},{value:"Unisolate",id:"unisolate",level:3},{value:"User Input Property",id:"user-input-property",level:3},{value:"Utilisation",id:"utilisation",level:3},{value:"Viewpoint",id:"viewpoint",level:3},{value:"Vignetting",id:"vignetting",level:3},{value:"Virtual Reality (VR)",id:"virtual-reality-vr",level:3},{value:"Visualisation",id:"visualisation",level:3},{value:"Visualised",id:"visualised",level:3},{value:"VR Discomfort",id:"vr-discomfort",level:3},{value:"VR Model",id:"vr-model",level:3},{value:"VR Sickness",id:"vr-sickness",level:3},{value:"Whitepoint",id:"whitepoint",level:3},{value:"Wildcard",id:"wildcard",level:3},{value:"Yaw",id:"yaw",level:3}];function h(e){const i={a:"a",h1:"h1",h3:"h3",header:"header",p:"p",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(i.header,{children:(0,a.jsx)(i.h1,{id:"glossary",children:"Glossary"})}),"\n",(0,a.jsx)(i.p,{children:"This page lists terminology that we use in our software and documentation. It includes both standard industry terms and terms specific to our products."}),"\n",(0,a.jsxs)(i.p,{children:[(0,a.jsx)(i.a,{href:"#ambient",children:"A"})," ",(0,a.jsx)(i.a,{href:"#bandwidth",children:"B"})," ",(0,a.jsx)(i.a,{href:"#cave-automatic-virtual-environment-cave",children:"C"})," ",(0,a.jsx)(i.a,{href:"#data-source",children:"D"})," ",(0,a.jsx)(i.a,{href:"#emissive",children:"E"})," ",(0,a.jsx)(i.a,{href:"#factory-reset",children:"F"})," ",(0,a.jsx)(i.a,{href:"#gallery",children:"G"})," ",(0,a.jsx)(i.a,{href:"#haptics",children:"H"})," ",(0,a.jsx)(i.a,{href:"#immersion",children:"I"})," ",(0,a.jsx)(i.a,{href:"#judder",children:"J"})," K ",(0,a.jsx)(i.a,{href:"#labels",children:"L"})," ",(0,a.jsx)(i.a,{href:"#map-matrix",children:"M"})," ",(0,a.jsx)(i.a,{href:"#networking",children:"N"})," ",(0,a.jsx)(i.a,{href:"#occlusion",children:"O"})," ",(0,a.jsx)(i.a,{href:"#pitch",children:"P"})," ",(0,a.jsx)(i.a,{href:"#quad-buffered",children:"Q"})," ",(0,a.jsx)(i.a,{href:"#reflectivity",children:"R"})," ",(0,a.jsx)(i.a,{href:"#saturation",children:"S"})," ",(0,a.jsx)(i.a,{href:"#teleportation",children:"T"})," ",(0,a.jsx)(i.a,{href:"#unisolate",children:"U"})," ",(0,a.jsx)(i.a,{href:"#viewpoint",children:"V"})," ",(0,a.jsx)(i.a,{href:"#whitepoint",children:"W"})," X ",(0,a.jsx)(i.a,{href:"#yaw",children:"Y"})," Z"]}),"\n",(0,a.jsx)(i.h3,{id:"ambient",children:"Ambient"}),"\n",(0,a.jsx)(i.p,{children:"How much light from ambient lights is reflected."}),"\n",(0,a.jsx)(i.h3,{id:"ancestor",children:"Ancestor"}),"\n",(0,a.jsx)(i.p,{children:"A node in a tree that is common to all of the nodes beneath it."}),"\n",(0,a.jsx)(i.h3,{id:"animation",children:"Animation"}),"\n",(0,a.jsx)(i.p,{children:"3D computer animation that combines 3D models of objects and programmed or hand keyframed movement."}),"\n",(0,a.jsx)(i.h3,{id:"animation-sequencer",children:"Animation Sequencer"}),"\n",(0,a.jsx)(i.p,{children:"The Animation Sequencer is a keyframe-based animation editor that permits you to create and edit animations. It is a tabbed window that consists of media controls, a properties panel, track list, timeline, and track view."}),"\n",(0,a.jsx)(i.h3,{id:"annotate",children:"Annotate"}),"\n",(0,a.jsx)(i.p,{children:"Add notes to a text or diagram, giving explanation or comment."}),"\n",(0,a.jsx)(i.h3,{id:"annotations",children:"Annotations"}),"\n",(0,a.jsx)(i.p,{children:"Annotations are product manufacturing information (PMI), typically text type but other types such as dimensions and symbology might also be considered annotations, which are added to designs in various CAD packages to convey additional information. Annotations can be used to add explanatory information for use in review but they are typically not a live tool that reviewers use for communication during a Design review process."}),"\n",(0,a.jsx)(i.h3,{id:"apps",children:"Apps"}),"\n",(0,a.jsx)(i.p,{children:"Applications these are platforms, software and tools that allow you to do a certain thing easily."}),"\n",(0,a.jsx)(i.h3,{id:"artifact",children:"Artifact"}),"\n",(0,a.jsx)(i.p,{children:"Typically Artifact is used internally when refering to managing data in the server systems. It can also be data results from applying a project to one or more data sources that can be visualised or utilised."}),"\n",(0,a.jsx)(i.h3,{id:"aspect-ratio",children:"Aspect Ratio"}),"\n",(0,a.jsxs)(i.p,{children:["Aspect ratio refers to the ratio of vertical lines of pixels to horizontal lines of pixels on a screen, i.e., the width of the screen as compared to the height of the screen, usually presented in form width",":height","."]}),"\n",(0,a.jsx)(i.h3,{id:"assembly",children:"Assembly"}),"\n",(0,a.jsx)(i.p,{children:"A runtime unit consisting of types and other resources."}),"\n",(0,a.jsx)(i.h3,{id:"assets",children:"Assets"}),"\n",(0,a.jsx)(i.p,{children:"Any digital file that is consumed within Visionary Render. Assets can include materials, models, particles, texture, audio, movies etc."}),"\n",(0,a.jsx)(i.h3,{id:"augmented-reality",children:"Augmented Reality"}),"\n",(0,a.jsx)(i.p,{children:"Augmented reality is a technology somewhat similar to virtual reality, but with a few key differences. Instead of trying to create an entirely separate world within the confines of VR gear and using it to replace the real world, it simply overlays visual or audio information over the real world as seen through the user's eyes. It presents information relevant to what the user is seeing at any given time, or filters out other objects, as per the user's needs. Although AR, like mixed reality technology, modifies the world in the user's eyes, unlike in mixed reality, AR modifications are purely informative and are neither anchored to nor do they interact with the real world."}),"\n",(0,a.jsx)(i.h3,{id:"avatar",children:"Avatar"}),"\n",(0,a.jsx)(i.p,{children:"A virtual representation of the experiencer within the virtual world."}),"\n",(0,a.jsx)(i.h3,{id:"bandwidth",children:"Bandwidth"}),"\n",(0,a.jsx)(i.p,{children:"The actual speed at which data is being transferred to and from your machine."}),"\n",(0,a.jsx)(i.h3,{id:"cave-automatic-virtual-environment-cave",children:"Cave Automatic Virtual Environment (CAVE)"}),"\n",(0,a.jsx)(i.p,{children:"A cave automatic virtual environment or CAVE uses projections on the walls and ceiling of a room to create the illusion of a real environment. A viewer can move around anywhere inside the cave, giving them the illusion of immersion. However, it is not possible to directly interact with the environment, since it consists only of projections and leaves the viewer feeling somewhat disconnected from their surroundings."}),"\n",(0,a.jsx)(i.h3,{id:"character-controller",children:"Character Controller"}),"\n",(0,a.jsx)(i.p,{children:"Allows you to easily do movement constrained by collisions, without having to deal with a rigid body."}),"\n",(0,a.jsx)(i.h3,{id:"chroma-keying",children:"Chroma Keying"}),"\n",(0,a.jsx)(i.p,{children:"A technique that removes selected colour hues from a video or image."}),"\n",(0,a.jsx)(i.h3,{id:"collision-detection",children:"Collision Detection"}),"\n",(0,a.jsx)(i.p,{children:"Detection that virtual objects have intersected, sometimes triggering haptic or visual feedback for the experiencer."}),"\n",(0,a.jsx)(i.h3,{id:"comments",children:"Comments"}),"\n",(0,a.jsx)(i.p,{children:"A system unique to Virtalis Reach but similar to the commenting features of packages such as Confluence and MS Word which enable users to collaborate and communicate asynchronously on visualisations by maintaining threads of conversation."}),"\n",(0,a.jsx)(i.h3,{id:"computer-aided-design-cad",children:"Computer-Aided Design (CAD)"}),"\n",(0,a.jsx)(i.p,{children:"Creating models on a computer or device using software such as AutoCAD."}),"\n",(0,a.jsx)(i.h3,{id:"data-source",children:"Data Source"}),"\n",(0,a.jsx)(i.p,{children:"A connection to a source of many items of External Data that are to be visualised."}),"\n",(0,a.jsx)(i.h3,{id:"data-source-adapter",children:"Data Source Adapter"}),"\n",(0,a.jsx)(i.p,{children:"An adapter between a data source and this system which supplies the types, identifiers, metadata and blobs of the External Data. May also enable data to be modified or inserted into the data source."}),"\n",(0,a.jsx)(i.h3,{id:"degrees-of-freedom-3dof-6dof",children:"Degrees of Freedom (3DOF, 6DOF)"}),"\n",(0,a.jsx)(i.p,{children:"Degrees of freedom or DOF refers to the different degrees of movement available to an object inside a space. There are six types of movement that can be further divided into translation (straight line movement in a specific direction) and rotation (a movement about the x-, y-, or z-axis) move sets. For instance, hitting a baseball with a baseball bat is not a single movement, but a complex combination of rotations and translations performed at the same time. An object can freely translate along each of the three perpendicular axes. These movements constitute the first three degrees of freedom: surge (forward and backward motion), heave (upward and downward motion), and sway (leftward and rightward motion). An object can also simultaneously rotate along the three axes. These movements constitute the other three degrees of freedom: roll (tilting from side to side), pitch (tilting forwards and backwards), and yaw (tilting left and right). Together these add up to six degrees of freedom or 6DOF and can describe every possible movement of an object."}),"\n",(0,a.jsx)(i.h3,{id:"diagnostics",children:"Diagnostics"}),"\n",(0,a.jsx)(i.p,{children:"A distinctive symptom or characteristic."}),"\n",(0,a.jsx)(i.h3,{id:"dimension",children:"Dimension"}),"\n",(0,a.jsx)(i.p,{children:"The distance between measuring points."}),"\n",(0,a.jsx)(i.h3,{id:"dual-gpu-parallel",children:"Dual GPU Parallel"}),"\n",(0,a.jsx)(i.p,{children:"GPU multicast - render both eyes in parallel on two GPU's."}),"\n",(0,a.jsx)(i.h3,{id:"emissive",children:"Emissive"}),"\n",(0,a.jsx)(i.p,{children:"Dictates what colour is emitted by the surface and how brightly that colour is emitted."}),"\n",(0,a.jsx)(i.h3,{id:"entity-filters",children:"Entity Filters"}),"\n",(0,a.jsx)(i.p,{children:"Node types to ignore and whether to override cull settings."}),"\n",(0,a.jsx)(i.h3,{id:"external-data",children:"External Data"}),"\n",(0,a.jsx)(i.p,{children:"Any item within a data source that can be translated to a Virtalis Model. Such as CAD components and Product Trees."}),"\n",(0,a.jsx)(i.h3,{id:"eye-tracking",children:"Eye Tracking"}),"\n",(0,a.jsx)(i.p,{children:"Eye tracking is a process used in headsets to measure and keep track of the direction of the user's gaze. Using this information, it is possible to reproduce the eyes natural process of bringing objects into/out of focus depending on what the user is concentrated on. Doing so enhances the feeling of immersion greatly, as simulating normal eye processes makes the users VR experience much more realistic and therefore less likely to break immersion."}),"\n",(0,a.jsx)(i.h3,{id:"factory-reset",children:"Factory Reset"}),"\n",(0,a.jsx)(i.p,{children:"Reset the settings to their default value when the application was installed."}),"\n",(0,a.jsx)(i.h3,{id:"fast-approximate-anti-aliasing-fxaa",children:"Fast Approximate Anti-aliasing (FXAA)"}),"\n",(0,a.jsx)(i.p,{children:"Applies a fast, approximate anti-aliasing technique to reduce jagged edges."}),"\n",(0,a.jsx)(i.h3,{id:"field-of-view-fov",children:"Field of View (FOV)"}),"\n",(0,a.jsx)(i.p,{children:"The field of view is the total number of degrees visible at any given moment from a given point of view. Most people's field of view is approximately 200."}),"\n",(0,a.jsx)(i.h3,{id:"frames-per-second-fps",children:"Frames per Second (FPS)"}),"\n",(0,a.jsx)(i.p,{children:"The number of individual images (frames) rendered per second. Keep in mind that this value is non-linear so Milliseconds per Frame is often preferable when performing a comparison."}),"\n",(0,a.jsx)(i.h3,{id:"frame-rate-30fps-and-60fps",children:"Frame Rate (30fps and 60fps)"}),"\n",(0,a.jsx)(i.p,{children:"Frame rates are the frequency at which an image/frame on a monitor is replaced by another. Each frame represents a still image to replace the previous image with, giving off the illusion of change/movement on a monitor. Generally, the two most common frame rates are 30 fps and 60fps, meaning 30 frames per second and 60 frames per second, respectively. The lower a frame rate, the fewer images are used to bridge the gap between a previous scene shown and the next one, meaning that lower frame rates imply more changes/movement between images and thus jerkier or choppier movement. In contrast, high frame rates create a feeling of smoothness, as they have the benefit of using more images with progressively smaller changes for each second of content."}),"\n",(0,a.jsx)(i.h3,{id:"gallery",children:"Gallery"}),"\n",(0,a.jsx)(i.p,{children:"A collection."}),"\n",(0,a.jsx)(i.h3,{id:"geometric-shapes",children:"Geometric Shapes"}),"\n",(0,a.jsx)(i.p,{children:"The forms of objects which have boundary lines, angles and surfaces."}),"\n",(0,a.jsx)(i.h3,{id:"graphical-user-interface-gui",children:"Graphical User Interface (GUI)"}),"\n",(0,a.jsx)(i.p,{children:"A graphics-based operating system interface that uses icons, menus and a mouse (to click on the icon or pull down the menus) to manage interaction with the system."}),"\n",(0,a.jsx)(i.h3,{id:"haptics",children:"Haptics"}),"\n",(0,a.jsx)(i.p,{children:"Haptics are a way of providing feedback to the user for actions taken in virtual reality environments, physically simulating the expected results of the user's movements, similar to vibration effects on controllers. When the user tries to grab or touch something in the VR setting, gloves or other gear worn by the user can simulate the pressure to the corresponding part of the user's body and make it feel like the user is touching a virtual object."}),"\n",(0,a.jsx)(i.h3,{id:"head-mounted-display-hmd",children:"Head Mounted Display (HMD)"}),"\n",(0,a.jsx)(i.p,{children:"A head mounted display or HMD refers to a VR headset, basically a set of lenses combined with either an inbuilt display or attached smartphone in the form of a helmet or goggles that can be strapped around your head. Some contain a variety of sensors that can track the movement of the head."}),"\n",(0,a.jsx)(i.h3,{id:"head-tracking",children:"Head Tracking"}),"\n",(0,a.jsx)(i.p,{children:"Head tracking is a process that monitors the current position and orientation of the user's head. This is extremely important in VR as it allows the virtual point of view to follow around the user's point of view, so the user can turn their head and see different angles of the same scene within the VR environment."}),"\n",(0,a.jsx)(i.h3,{id:"head-up-display-hud",children:"Head-Up Display (HUD)"}),"\n",(0,a.jsx)(i.p,{children:"The Heads-Up-Display is a way of showing data to the user without forcing them to look away from their current position, improving the user's ability to view and identify relevant information and lowering the time it takes to do so."}),"\n",(0,a.jsx)(i.h3,{id:"headlight",children:"Headlight"}),"\n",(0,a.jsx)(i.p,{children:"Light that points in the view direction of the camera."}),"\n",(0,a.jsx)(i.h3,{id:"heatmap",children:"Heatmap"}),"\n",(0,a.jsx)(i.p,{children:"A heatmap is an analytical tool used to show what a user is looking at within a VR experience, graphical interface etc., It uses a system of color-coding, usually ranging from red (hot) to blue or green (cold), to create a graphical representation of the focus of the user's attention."}),"\n",(0,a.jsx)(i.h3,{id:"helpers",children:"Helpers"}),"\n",(0,a.jsx)(i.p,{children:"Manipulators that are rendered in the 3D scene to enable one to tweak the emission shape of the particle system."}),"\n",(0,a.jsx)(i.h3,{id:"high-definition-rendering-hdr",children:"High-Definition Rendering (HDR)"}),"\n",(0,a.jsx)(i.p,{children:"Reproduce a higher dynamic range of luminosity. This typically makes the scene appear brighter."}),"\n",(0,a.jsx)(i.h3,{id:"immersion",children:"Immersion"}),"\n",(0,a.jsx)(i.p,{children:"Immersion is the viewer's sense of being part of a virtual environment. It is achieved when sound, design, atmosphere, visualisation, etc. are able to create a sense of actually being in the virtual world."}),"\n",(0,a.jsx)(i.h3,{id:"import",children:"Import"}),"\n",(0,a.jsx)(i.p,{children:"Bringing in information from a file into a program."}),"\n",(0,a.jsx)(i.h3,{id:"interpupillary-distance-ipd",children:"Interpupillary Distance (IPD)"}),"\n",(0,a.jsx)(i.p,{children:"Distance between the centre of the pupils in your eyes."}),"\n",(0,a.jsx)(i.h3,{id:"input",children:"Input"}),"\n",(0,a.jsx)(i.p,{children:"Put refers to the method of control you will use for virtual reality. This could be a mouse and keyboard, a gamepad, or even motion-tracking."}),"\n",(0,a.jsx)(i.h3,{id:"interpolation",children:"Interpolation"}),"\n",(0,a.jsx)(i.p,{children:"The creation of new values that lie between known values."}),"\n",(0,a.jsx)(i.h3,{id:"isolate",children:"Isolate"}),"\n",(0,a.jsx)(i.p,{children:"Functionality wherein users can identify an assembly/sub-assembly/component and examine or deal with it separately."}),"\n",(0,a.jsx)(i.h3,{id:"judder",children:"Judder"}),"\n",(0,a.jsx)(i.p,{children:"Judder is a significant shaking of the visual content within the Head Mounted Display."}),"\n",(0,a.jsx)(i.h3,{id:"labels",children:"Labels"}),"\n",(0,a.jsx)(i.p,{children:"A set of predefined and free-form tags that are associated with a project. These may include the  proposed goal or outcome for a project that may be picked up in different places in this system to tune the behaviour for the outcome. It also provides labels that can be used to link related projects for example to present a list of training scenarios. For example a particular project might have labels indicating #HMD #Training #Welding."}),"\n",(0,a.jsx)(i.h3,{id:"last-world-click",children:"Last World Click"}),"\n",(0,a.jsx)(i.p,{children:"The absolute position of the last mouse click."}),"\n",(0,a.jsx)(i.h3,{id:"latency",children:"Latency"}),"\n",(0,a.jsx)(i.p,{children:"Latency in virtual reality refers to a delay between user input (e.g., head, hand, or leg movements) and output (e.g., visual, haptic, positional, audio) caused by a mixture of technical problems. High-latency can lead to a detached experience and can also contribute to motion sickness / dizziness."}),"\n",(0,a.jsx)(i.h3,{id:"level-of-detail-lod",children:"Level of Detail (LOD)"}),"\n",(0,a.jsx)(i.p,{children:"Multi-resolution mesh data that is referenced by a mesh node in a VR Model."}),"\n",(0,a.jsx)(i.h3,{id:"locomotion",children:"Locomotion"}),"\n",(0,a.jsx)(i.p,{children:"Locomotion refers to the means by which the user is able to move around within a VR environment. Most systems use some combination of three different types of locomotion: teleportation, transportation, and perambulation. Teleportation allows the user to point and click on a location to teleport there or select from a predefined list of locations to travel to, giving them a certain freedom of movement but no option for movement in between locations. Transportation makes the user a passenger in a vehicle or on an animal that moves along a predefined path, allowing them to move their head or hands, but making them unable to move away from their mode of transportation in any way beyond choosing a different object to follow. Perambulation uses handheld controllers, the HMD, or room-tracking to track the user's movements and give them the ability to move as they would in the real world."}),"\n",(0,a.jsx)(i.h3,{id:"lua",children:"Lua"}),"\n",(0,a.jsx)(i.p,{children:"Lua is a lightweight, high-level, multi-paradigm programming language designed primarily for embedded use in applications. Lua is cross-platform, since the interpreter of compiled bytecode is written in ANSI C, and Lua has a relatively simple C API to embed it into applications."}),"\n",(0,a.jsx)(i.h3,{id:"map-matrix",children:"Map Matrix"}),"\n",(0,a.jsx)(i.p,{children:"Provides control over how the textures are mapped into a Model."}),"\n",(0,a.jsx)(i.h3,{id:"material",children:"Material"}),"\n",(0,a.jsx)(i.p,{children:"Used to describe the surface appearance of a Model."}),"\n",(0,a.jsx)(i.h3,{id:"merge",children:"Merge"}),"\n",(0,a.jsx)(i.p,{children:"Combine or cause to combine to form a single entity."}),"\n",(0,a.jsx)(i.h3,{id:"metadata",children:"Metadata"}),"\n",(0,a.jsx)(i.p,{children:"A set of data that describes and gives information about other data."}),"\n",(0,a.jsx)(i.h3,{id:"mixed-reality",children:"Mixed Reality"}),"\n",(0,a.jsx)(i.p,{children:"Mixed reality technology overlays artificial content onto the real world and enables the artificial content to interact with the real world scenery. Additionally, mixed reality allows overlaid content to be interacted with in real time, as it stays continually updated for interactivity."}),"\n",(0,a.jsx)(i.h3,{id:"networking",children:"Networking"}),"\n",(0,a.jsx)(i.p,{children:"The practice of transporting and exchanging data between nodes over a shared medium in an information system."}),"\n",(0,a.jsx)(i.h3,{id:"node",children:"Node"}),"\n",(0,a.jsx)(i.p,{children:"Devide or data point in a larger network."}),"\n",(0,a.jsx)(i.h3,{id:"occlusion",children:"Occlusion"}),"\n",(0,a.jsx)(i.p,{children:"The obscuring or hiding an object from view by the positioning of other objects in the experiencer's line of sight."}),"\n",(0,a.jsx)(i.h3,{id:"opacity",children:"Opacity"}),"\n",(0,a.jsx)(i.p,{children:"Dictates how opaque the surface is."}),"\n",(0,a.jsx)(i.h3,{id:"pitch",children:"Pitch"}),"\n",(0,a.jsx)(i.p,{children:"Rotation around the horizontal (x) axis."}),"\n",(0,a.jsx)(i.h3,{id:"pivot",children:"Pivot"}),"\n",(0,a.jsx)(i.p,{children:"The central point, pin, or shaft on which a mechanism turns or oscillates."}),"\n",(0,a.jsx)(i.h3,{id:"plugin",children:"Plugin"}),"\n",(0,a.jsx)(i.p,{children:"Software that adds new functions to a host program without altering the host program itself."}),"\n",(0,a.jsx)(i.h3,{id:"point-of-view-pov",children:"Point of View (POV)"}),"\n",(0,a.jsx)(i.p,{children:"The point of view or POV is the reference point from which observations, calculations, and measurements take place; the location or position of the viewer/object in question."}),"\n",(0,a.jsx)(i.h3,{id:"position-tracking",children:"Position Tracking"}),"\n",(0,a.jsx)(i.p,{children:"The ability to track where you are in a physical space e.g. moving around a room."}),"\n",(0,a.jsx)(i.h3,{id:"positional-audio",children:"Positional Audio"}),"\n",(0,a.jsx)(i.p,{children:"Positional audio is an audio technique that ties sounds to specific sources within an environment, realistically simulating the things the listener would hear from their point of view. This means that sounds will always come from the expected position relative to the listener."}),"\n",(0,a.jsx)(i.h3,{id:"precision",children:"Precision"}),"\n",(0,a.jsx)(i.p,{children:"The number of significant figures to show for each measurement."}),"\n",(0,a.jsx)(i.h3,{id:"product-lifecycle-management-plm-database",children:"Product Lifecycle Management (PLM) Database"}),"\n",(0,a.jsx)(i.p,{children:"A subclass of of data source whose External Data are Components (CAD) and Product Trees (CAD) under Product Lifecycle Management."}),"\n",(0,a.jsx)(i.h3,{id:"project",children:"Project"}),"\n",(0,a.jsx)(i.p,{children:"A object containing an ordered list of templates and references to VR Models, which may be either specific or a based on a pattern."}),"\n",(0,a.jsx)(i.h3,{id:"properties",children:"Properties"}),"\n",(0,a.jsx)(i.p,{children:"Settings of an object on a computer."}),"\n",(0,a.jsx)(i.h3,{id:"property-tracks",children:"Property Tracks"}),"\n",(0,a.jsx)(i.p,{children:"Designed to make one animate non-transform values."}),"\n",(0,a.jsx)(i.h3,{id:"prs-manipulator",children:"PRS Manipulator"}),"\n",(0,a.jsx)(i.p,{children:"3D widget that enables you to change the position, rotation and scale of the selected object."}),"\n",(0,a.jsx)(i.h3,{id:"quad-buffered",children:"Quad Buffered"}),"\n",(0,a.jsx)(i.p,{children:"Standard OpenGL stereo mode."}),"\n",(0,a.jsx)(i.h3,{id:"reflectivity",children:"Reflectivity"}),"\n",(0,a.jsx)(i.p,{children:"The percentage of light that is reflected straight back at the light when the surface is directly facing the light, and inversely how much light is scattered instead."}),"\n",(0,a.jsx)(i.h3,{id:"resolution-1080p---16k",children:"Resolution (1080p - 16K)"}),"\n",(0,a.jsx)(i.p,{children:"Image resolution refers to the degree of detail an image holds, represented by the number of pixels. Higher resolutions make images sharper, as they increase the number of pixels used to represent images, which adds more detail to them. Screen size can drastically affect the sharpness of an image; if the screen is small enough, even low-resolution images can become nearly identical to far higher-resolution images."}),"\n",(0,a.jsx)(i.h3,{id:"review",children:"Review"}),"\n",(0,a.jsx)(i.p,{children:"An activity whereby one or more users critique a visualisation. Particularly a Design Review where subject matter experts, managers and other stakeholders will critique a CAD design and ensure it is fit for its intended purpose. For example to identify issues that may prevent it being manufactured. The output of a review is captured in a variety of ways, Virtalis Reach has Comments to streamline that."}),"\n",(0,a.jsx)(i.h3,{id:"rule",children:"Rule"}),"\n",(0,a.jsx)(i.p,{children:"An object that transforms VR Models based on certain conditions and logic, increasing the effectiveness by which the data is communicated by visualisation."}),"\n",(0,a.jsx)(i.h3,{id:"saturation",children:"Saturation"}),"\n",(0,a.jsx)(i.p,{children:"Controls the intensity of colours in the rendered image."}),"\n",(0,a.jsx)(i.h3,{id:"sequencer",children:"Sequencer"}),"\n",(0,a.jsx)(i.p,{children:"Generates visuals in the scene to show the animation paths of targets and to permit keyframe positions to be edited visually."}),"\n",(0,a.jsx)(i.h3,{id:"sequences",children:"Sequences"}),"\n",(0,a.jsx)(i.p,{children:"A particular order in which related things follow each other."}),"\n",(0,a.jsx)(i.h3,{id:"side-by-side-anamorphic",children:"Side-by-Side: Anamorphic"}),"\n",(0,a.jsx)(i.p,{children:"Left half window is left eye, right half is right eye. Pixels are 2:1 ratio."}),"\n",(0,a.jsx)(i.h3,{id:"side-by-side-square",children:"Side-by-Side: Square"}),"\n",(0,a.jsx)(i.p,{children:"Left half window is left eye, right half is right eye. Pixels are square."}),"\n",(0,a.jsx)(i.h3,{id:"signposts",children:"Signposts"}),"\n",(0,a.jsx)(i.p,{children:"Environment cues with the added purpose of helping the user to interpret the virtual environment."}),"\n",(0,a.jsx)(i.h3,{id:"single-gpu-parallel",children:"Single GPU Parallel"}),"\n",(0,a.jsx)(i.p,{children:"Singe-pass stereo - render both eyes in parallel on the primary GPU."}),"\n",(0,a.jsx)(i.h3,{id:"smoothness",children:"Smoothness"}),"\n",(0,a.jsx)(i.p,{children:"How smooth or rough the surface is."}),"\n",(0,a.jsx)(i.h3,{id:"snap",children:"Snap"}),"\n",(0,a.jsx)(i.p,{children:"A fraction."}),"\n",(0,a.jsx)(i.h3,{id:"snapshot",children:"Snapshot"}),"\n",(0,a.jsx)(i.p,{children:"Store the states of objects in the scene such as their position and visibility."}),"\n",(0,a.jsx)(i.h3,{id:"software-development-kit-sdk",children:"Software Development Kit (SDK)"}),"\n",(0,a.jsx)(i.p,{children:"A range of tools or a platform allowing developers to create software or technology for themselves."}),"\n",(0,a.jsx)(i.h3,{id:"start-room",children:"Start Room"}),"\n",(0,a.jsx)(i.p,{children:"When Visionary Render is initialised, you will be presented with the Start Room. This is a simple scene of a fictional room. It is designed to help you become accustomed to a virtual environment, to determine the visual fidelity that your machine can support, and to configure tracking systems before loading your data."}),"\n",(0,a.jsx)(i.h3,{id:"stereo-3d",children:"Stereo 3D"}),"\n",(0,a.jsx)(i.p,{children:"3D in stereo mode."}),"\n",(0,a.jsx)(i.h3,{id:"stereo-cursor",children:"Stereo Cursor"}),"\n",(0,a.jsx)(i.p,{children:"The 3D cursor in Visionary Render."}),"\n",(0,a.jsx)(i.h3,{id:"stereoscopic",children:"Stereoscopic"}),"\n",(0,a.jsx)(i.p,{children:"Stereoscopic refer to the ability to view object in a Head Mounted Display with the illusion of depth. It is usally achieved through different processes by which an object and/or environment is captured with different angles (representing left and right eye) are viewed together, creating an impression of depth and solidity."}),"\n",(0,a.jsx)(i.h3,{id:"teleportation",children:"Teleportation"}),"\n",(0,a.jsx)(i.p,{children:"Moving across the virtual space without physically moving in the real world."}),"\n",(0,a.jsx)(i.h3,{id:"template",children:"Template"}),"\n",(0,a.jsx)(i.p,{children:"An object that transforms VR Models using rules and other assets, increasing the effectiveness by which the data is communicated by visualisation."}),"\n",(0,a.jsx)(i.h3,{id:"tethered-headset--mobile-headset",children:"Tethered Headset / Mobile Headset"}),"\n",(0,a.jsx)(i.p,{children:"There are currently two different types of headsets for VR: tethered and mobile. Tethered headsets are physically connected to a powerful computer using wires, allowing them to make use of the processing power available to track positions, movements, etc. Tethered headsets give the user a freedom of movement beyond turning their heads and additional interactivity. However, they require the user to stay within a certain distance of the computer, as the user's headset must stay connected physically to the computer, and are relatively expensive compared to their mobile counterparts. Mobile headsets can be taken anywhere, since they do not require a physical connection to a processor, and are far cheaper than tethered headsets."}),"\n",(0,a.jsx)(i.h3,{id:"texture",children:"Texture"}),"\n",(0,a.jsx)(i.p,{children:"Image that can be loaded into Visionary Render and used in Materials to provide more realistic surface finishes."}),"\n",(0,a.jsx)(i.h3,{id:"timeline",children:"Timeline"}),"\n",(0,a.jsx)(i.p,{children:"Indicates the positions of Frames, Animations, and other Sequences within a sequence."}),"\n",(0,a.jsx)(i.h3,{id:"timings",children:"Timings"}),"\n",(0,a.jsx)(i.p,{children:"Current frame rate in Hertz, the time to render the last frame in milliseconds, and how many millions of triangles are drawn per second."}),"\n",(0,a.jsx)(i.h3,{id:"toolbar",children:"Toolbar"}),"\n",(0,a.jsx)(i.p,{children:"The tool bar is the primary GUI that contains the Application Menu and various buttons. Many of the buttons represent tools that can be on or off. These are highlighted in orange when they are activated. The buttons with a small orange triangle at their bottom right contain drop-down menu."}),"\n",(0,a.jsx)(i.h3,{id:"tracking",children:"Tracking"}),"\n",(0,a.jsx)(i.p,{children:"Leaves traces of the movement."}),"\n",(0,a.jsx)(i.h3,{id:"transformation",children:"Transformation"}),"\n",(0,a.jsx)(i.p,{children:"The activity by which VR Models are transformed to increase their effectiveness for visualisation."}),"\n",(0,a.jsx)(i.h3,{id:"translation",children:"Translation"}),"\n",(0,a.jsx)(i.p,{children:"The activity by which External Data is translated to VR Models."}),"\n",(0,a.jsx)(i.h3,{id:"unisolate",children:"Unisolate"}),"\n",(0,a.jsx)(i.p,{children:"Functionality wherein users can revert back to overall view from isolation."}),"\n",(0,a.jsx)(i.h3,{id:"user-input-property",children:"User Input Property"}),"\n",(0,a.jsx)(i.p,{children:"Allows scripts to invoke the player to send remote control data to the server."}),"\n",(0,a.jsx)(i.h3,{id:"utilisation",children:"Utilisation"}),"\n",(0,a.jsx)(i.p,{children:"The activity by which a artifact is consumed non-visually. For example to enable it to be further manipulated to be consumed externally."}),"\n",(0,a.jsx)(i.h3,{id:"viewpoint",children:"Viewpoint"}),"\n",(0,a.jsx)(i.p,{children:"Type of assembly used to store an interesting or important view in the scene."}),"\n",(0,a.jsx)(i.h3,{id:"vignetting",children:"Vignetting"}),"\n",(0,a.jsx)(i.p,{children:"Controls the image brightness in the image periphery compared to the image centre."}),"\n",(0,a.jsx)(i.h3,{id:"virtual-reality-vr",children:"Virtual Reality (VR)"}),"\n",(0,a.jsx)(i.p,{children:"Virtual reality is a technology that, unlike augmented reality, creates an artificial world for the user to experience."}),"\n",(0,a.jsx)(i.h3,{id:"visualisation",children:"Visualisation"}),"\n",(0,a.jsx)(i.p,{children:"The activity by which an artifact is consumed visually.\r\nThe activity by which data is effectively communicated using visual techniques and graphics.\r\nThis system seeks to empower organisations to communicate effectively by enabling a common visual language powered by visualisation.\r\n(see also Visualisation / Data )."}),"\n",(0,a.jsx)(i.h3,{id:"visualised",children:"Visualised"}),"\n",(0,a.jsx)(i.p,{children:"The act of consuming or presenting data using visualisation."}),"\n",(0,a.jsx)(i.h3,{id:"vr-discomfort",children:"VR Discomfort"}),"\n",(0,a.jsx)(i.p,{children:"considered a subset of motion sickness. It is often the result of perceived discrepancies between what your brain and body think they're doing. It can be induced without actual motion. Symptoms of VR discomfort include apathy, drowsiness, disorientation, fatigue, and vomiting and we recommend removing a VR headset if you begin to experience such discomfort."}),"\n",(0,a.jsx)(i.h3,{id:"vr-model",children:"VR Model"}),"\n",(0,a.jsx)(i.p,{children:"Data which results from the translation of an External Data.A VR Model may reference another VR Model. A VR Model consists of a graph of nodes with properties, linked with parent-child relationships and in tranode references."}),"\n",(0,a.jsx)(i.h3,{id:"vr-sickness",children:"VR Sickness"}),"\n",(0,a.jsx)(i.p,{children:"Virtual reality sickness is a feeling of discomfort or disorientation that can occur when experiencing virtual environments. There are several theories on its causes, mostly related to the small but noticeable gap between virtual reality and reality."}),"\n",(0,a.jsx)(i.h3,{id:"whitepoint",children:"Whitepoint"}),"\n",(0,a.jsx)(i.p,{children:"Specifies the main colour temperature of the light sources."}),"\n",(0,a.jsx)(i.h3,{id:"wildcard",children:"Wildcard"}),"\n",(0,a.jsx)(i.p,{children:"A symbol used to replace or represent one or more character."}),"\n",(0,a.jsx)(i.h3,{id:"yaw",children:"Yaw"}),"\n",(0,a.jsx)(i.p,{children:"Rotation around the vertical (y) axis."})]})}function c(e={}){const{wrapper:i}={...(0,r.R)(),...e.components};return i?(0,a.jsx)(i,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},28453:(e,i,t)=>{t.d(i,{R:()=>s,x:()=>o});var n=t(96540);const a={},r=n.createContext(a);function s(e){const i=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),n.createElement(r.Provider,{value:i},e.children)}}}]);